# FLPerformance Architecture

## Overview

FLPerformance is a full-stack application designed to benchmark multiple Large Language Models (LLMs) running via Microsoft Foundry Local. The application follows a clean separation of concerns with distinct layers for UI, API, orchestration, benchmarking, and storage.

## ğŸ‰ Current Status (January 2026)

### âœ… Successfully Implemented
- **Enhanced Frontend**: Comprehensive visualizations with performance cards, charts, and radar graphs
- **Backend Integration**: Fixed critical model loading bug (alias â†’ model_id lookup)
- **Benchmark System**: Fully functional with proper data structures and hardware detection
- **Results Display**: Rich comparison tables, statistics cards, and recent runs tracking
- **ARM64 Hardware Detection**: Proper Snapdragon X Elite system recognition

### âš ï¸ Known Compatibility Issue
- **Foundry Local ARM64**: Service initialization issues on Windows ARM64 systems
- **Impact**: Visualizations and benchmark system work perfectly, but model inference is blocked
- **Workaround**: Consider alternative model serving or x64 systems for full functionality

## System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Frontend (React)                      â”‚
â”‚  - Dashboard                                                  â”‚
â”‚  - Models Management                                          â”‚
â”‚  - Benchmarks Configuration                                   â”‚
â”‚  - Results Visualization                                      â”‚
â”‚  - Settings                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ HTTP/REST API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Backend API (Express.js)                   â”‚
â”‚  - RESTful endpoints for models, benchmarks, results         â”‚
â”‚  - Request validation and error handling                     â”‚
â”‚  - Static file serving (production)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Foundry Local    â”‚    â”‚  Benchmark Engine  â”‚
â”‚   Orchestrator    â”‚    â”‚                    â”‚
â”‚                   â”‚    â”‚  - Run scenarios   â”‚
â”‚  - Start/stop     â”‚    â”‚  - Collect metrics â”‚
â”‚    services       â”‚    â”‚  - Calculate stats â”‚
â”‚  - Load models    â”‚    â”‚  - Resource mon.   â”‚
â”‚  - Health checks  â”‚    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  - OpenAI client  â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
       â”‚                        â”‚
       â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚    â”‚   Storage Layer             â”‚
       â”‚    â”‚   - JSON file storage       â”‚
       â””â”€â”€â”€â”€â–º   - SQLite (optional)       â”‚
            â”‚   - Structured logging      â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚   Foundry Local Service      â”‚
       â”‚   (Single service instance)  â”‚
       â”‚   - Multiple model loading   â”‚
       â”‚   - OpenAI-compatible API    â”‚
       â”‚   - Model differentiation    â”‚
       â”‚     by ID in requests        â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Component Details

### 1. Frontend (React + Vite)

**Location:** `/src/client`

**Responsibilities:**
- User interface for all application features
- Real-time status updates
- Interactive charts and data visualization
- Form handling and validation

**Key Pages:**
- **Dashboard:** Overview statistics and quick actions
- **Models:** Add/remove models, start/stop services, view logs
- **Benchmarks:** Configure and run benchmark suites
- **Results:** View, filter, compare, and export benchmark results
- **Settings:** Application configuration and information

**Technology Stack:**
- React 18 for UI components
- React Router for navigation
- Recharts for data visualization
- Axios for API communication
- Vite for development and build tooling

### 2. Backend API (Express.js)

**Location:** `/src/server/index.js`

**Responsibilities:**
- Expose RESTful API endpoints
- Route requests to appropriate services
- Handle errors and return consistent responses
- Serve static frontend in production

**API Endpoints:**

**Models:**
- `GET /api/models/available` - List available models from Foundry Local
- `GET /api/models` - List configured models
- `POST /api/models` - Add new model
- `DELETE /api/models/:id` - Remove model
- `POST /api/models/:id/start` - Start service
- `POST /api/models/:id/stop` - Stop service
- `POST /api/models/:id/load` - Load model
- `GET /api/models/:id/health` - Health check
- `GET /api/models/:id/logs` - Get service logs

**Benchmarks:**
- `GET /api/benchmarks/suites` - List benchmark suites
- `POST /api/benchmarks/run` - Run benchmark
- `GET /api/benchmarks/runs` - List all runs
- `GET /api/benchmarks/runs/:id` - Get run details
- `GET /api/benchmarks/results` - Get results (with filters)
- `GET /api/benchmarks/runs/:id/export/json` - Export as JSON
- `GET /api/benchmarks/runs/:id/export/csv` - Export as CSV
- `GET /api/benchmarks/runs/:id/logs` - Get run logs

**System:**
- `GET /api/system/health` - System health check
- `GET /api/system/stats` - Dashboard statistics

### 3. Foundry Local Orchestrator

**Location:** `/src/server/orchestrator.js`

**Responsibilities:**
- Interface with Foundry Local SDK (foundry-local-sdk)
- Manage single service instance with multiple models
- Maintain OpenAI-compatible client for the shared endpoint
- Handle model loading/unloading on-demand
- Perform health checks and service initialization

**Key Operations:**
- `initialize()` - Set up FoundryLocalManager and start service
- `listAvailableModels()` - Query models from Foundry Local catalog
- `listLoadedModels()` - Get currently loaded models
- `loadModel(modelId, alias)` - Load model into the shared service
- `unloadModel(modelId, alias)` - Unload model from service
- `getOpenAIClient()` - Get OpenAI client for inference
- `cleanup()` - Graceful shutdown and model unloading

**Service Architecture:**
- Single FoundryLocalManager instance
- Single service endpoint (e.g., http://127.0.0.1:58123/v1)
- Multiple models loaded simultaneously
- Model differentiation by alias in API calls
- Shared resource management

**Critical Fix Applied (January 2026):**
Fixed model lookup in API endpoints from `model.alias || model.model_id` to `model.model_id || model.alias` to ensure Foundry Local receives the correct model identifier.

### 4. Benchmark Engine

**Location:** `/src/server/benchmark.js`

**Responsibilities:**
- Execute benchmark scenarios
- Measure performance metrics
- Collect system resource data
- Calculate aggregate statistics
- Persist results to storage

**Key Metrics:**
- **Throughput (TPS):** Overall tokens per second
- **Time to First Token (TTFT):** Initial response time (streaming only)
- **Time Per Output Token (TPOT):** Average inter-token delay after first token (streaming only)
- **Generation TPS (GenTPS):** Token generation rate = 1000/TPOT (streaming only)
- **Latency:** P50/P95/P99 end-to-end completion time
- **Stability:** Error rate, timeout rate
- **Resources:** CPU, RAM, GPU utilization (best-effort)

**Benchmark Flow:**
1. Load benchmark suite definition
2. For each model:
   - Check service health
   - For each scenario:
     - Run N iterations
     - Collect resource metrics before/after
     - Measure latency and token output
     - Record errors and timeouts
   - Calculate aggregate statistics
   - Persist results
3. Mark run as completed

**Resource Monitoring:**
- Uses `systeminformation` library
- Captures CPU load percentage
- Captures RAM usage percentage
- Captures GPU utilization (if available)
- Cross-platform support with graceful degradation

### 5. Storage Layer

**Location:** `/src/server/storage.js`

**Responsibilities:**
- Persist application data
- Provide query interface
- Export results in multiple formats
- Maintain audit logs

**Database Schema (SQLite):**

**models**
- id, alias, model_id, endpoint, status, last_error, last_heartbeat, created_at, updated_at

**benchmark_runs**
- id, suite_name, model_ids (JSON), config (JSON), hardware_info (JSON), status, started_at, completed_at

**benchmark_results**
- id, run_id, model_id, scenario, tps, ttft, tpot, gen_tps, latency_p50, latency_p95, latency_p99, error_rate, timeout_rate, cpu_avg, ram_avg, gpu_avg, raw_data (JSON)

**logs**
- id, entity_type, entity_id, level, message, metadata (JSON), created_at

**Export Formats:**
- JSON: Full run + results with metadata
- CSV: Flattened results table

### 6. Logging System

**Location:** `/src/server/logger.js`

**Responsibilities:**
- Structured logging with Winston
- Service-specific and benchmark-specific loggers
- Console output with formatting
- Log level management

**Log Levels:**
- error: Critical failures
- warn: Recoverable issues
- info: General information
- debug: Detailed diagnostics

## Data Flow

### Starting a Model Service

```
User â†’ Frontend â†’ POST /api/models/:id/start
  â†’ Orchestrator.startService()
    â†’ Spawn Foundry Local process with dynamic port
    â†’ Wait for service readiness
    â†’ Create OpenAI client
    â†’ Update database status
  â†’ Return endpoint to frontend
```

### Running a Benchmark

```
User â†’ Frontend â†’ POST /api/benchmarks/run
  â†’ Backend validates request
  â†’ Benchmark Engine starts async execution
    â†’ Collect hardware info
    â†’ For each model:
      â†’ Check health
      â†’ For each scenario:
        â†’ Run iterations
        â†’ Measure metrics
        â†’ Collect resources
        â†’ Save results
    â†’ Mark run complete
  â†’ Frontend polls for results via GET /api/benchmarks/runs/:id
```

### Viewing Results

```
User â†’ Frontend â†’ GET /api/benchmarks/runs/:id
  â†’ Storage retrieves run + results
  â†’ Frontend renders:
    - Comparison table
    - TPS chart
    - Latency chart
    - Best model cards
```

## ARM64 Compatibility Status

### Current Issue (January 2026)

**Platform:** Windows 11 ARM64 (Snapdragon X Elite)
**Foundry Local Version:** 0.8.117

**Problem:**
- FoundryLocalManager initializes successfully
- Service endpoint is reported as available (http://127.0.0.1:58123/v1)
- Models can be "loaded" without errors
- However, the actual service doesn't accept HTTP connections
- All inference requests fail with connection refused/timeout

**Application Status:**
- âœ… **Frontend Components**: All visualizations, charts, and UI work perfectly
- âœ… **Backend API**: All endpoints functional, data processing works
- âœ… **Benchmark Engine**: Properly structured, ready for inference calls
- âœ… **Storage**: JSON and SQLite storage both functional
- âŒ **Model Inference**: Blocked by Foundry Local service connectivity

**Workarounds:**
1. **Development/Testing**: Use the application on x64 Windows systems
2. **Alternative Backends**: Consider Ollama, ONNX Runtime, or Hugging Face Transformers
3. **Mock Data**: Application can display results using sample data

## Scalability Considerations

### Current Limitations

1. **Sequential Benchmarking:** Models are benchmarked one at a time to avoid resource contention
2. **Single Machine:** All services run on the same machine
3. **Memory Constraints:** Limited by available RAM for model loading
4. **Port Availability:** Limited by available local ports (base 5000+)

### Future Enhancements

1. **Parallel Benchmarking:** Run benchmarks on multiple models simultaneously (if resources allow)
2. **Distributed Services:** Support remote Foundry Local services
3. **Result Aggregation:** Combine results from multiple benchmark runs
4. **Real-time Updates:** WebSocket integration for live progress
5. **Advanced Metrics:** Memory profiling, network I/O, disk usage

## Security Considerations

1. **Local-Only:** Designed for local development/testing
2. **No Authentication:** Assumes trusted local environment
3. **API Keys:** Placeholder keys for Foundry Local (adjust as needed)
4. **Process Isolation:** Each model service runs in separate process
5. **Resource Limits:** No enforced limits (rely on OS/hardware)

## Error Handling

**Frontend:**
- Try-catch on all API calls
- User-friendly error messages
- Success notifications

**Backend:**
- Global error handler middleware
- Structured error responses
- Error logging with context

**Orchestrator:**
- Process error event handlers
- Timeout handling
- Service restart capability (future)

**Benchmark Engine:**
- Per-scenario error isolation
- Timeout detection
- Graceful degradation

## Configuration

**Environment Variables:**
- `PORT` - API server port (default: 3001)
- `NODE_ENV` - Environment (development/production)
- `LOG_LEVEL` - Logging level (default: info)

**Runtime Configuration:**
- Benchmark iterations
- Timeout values
- Temperature
- Streaming mode

## Deployment

**Development:**
```bash
npm run dev  # Start both frontend and backend
```

**Production:**
```bash
npm run build  # Build frontend
npm start      # Start production server
```

**Prerequisites:**
- Node.js 18+
- Foundry Local installed and in PATH
- Adequate system resources for models

## Monitoring & Debugging

**Health Checks:**
- `/api/system/health` - Overall system status
- `/api/models/:id/health` - Per-model service health

**Logs:**
- Service logs: `/api/models/:id/logs`
- Benchmark logs: `/api/benchmarks/runs/:id/logs`
- Console output: Winston formatted logs

**Database:**
- SQLite at `/results/benchmarks.db`
- Query directly for troubleshooting

## Technology Stack Summary

**Frontend:**
- React 18.2
- React Router 6.20
- Recharts 2.10 (for enhanced visualizations)
- Axios 1.6
- Vite 5.0

**Backend:**
- Node.js (ES modules)
- Express 4.18
- foundry-local-sdk (official Microsoft SDK)
- Better-SQLite3 9.2 (optional, JSON fallback available)
- Winston 3.11
- OpenAI SDK 4.24
- Systeminformation 5.21

**Development:**
- Concurrently for parallel processes
- Vite dev server with HMR
- Express middleware for CORS

**Recent Enhancements (January 2026):**
- Enhanced Results.jsx with comprehensive visualizations
- Performance score cards (0-100 scale)
- Benchmark history with statistics
- Improved error handling and logging
- Fixed critical model loading bug

---

## Benchmark Execution Workflow

### Complete Benchmark Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. User Prepares Models                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚ Add Model            â”‚
                â”‚ (alias + model_id)   â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚ Load Model           â”‚
                â”‚ - Downloads if neededâ”‚
                â”‚ - Loads into Foundry â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚ âœ¨ Test Model âœ¨     â”‚
                â”‚ (NEW - Verify works) â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. User Runs Benchmark                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚ Select Models        â”‚
                â”‚ Select Suite         â”‚
                â”‚ Configure Settings   â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚ Start Benchmark      â”‚
                â”‚ (POST /benchmarks)   â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Benchmark Engine Execution                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                       â”‚
    For Each Model                    For Each Scenario
        â”‚                                       â”‚
        â–¼                                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Validate Model â”‚                    â”‚ Run Iterations â”‚
â”‚ - Check storageâ”‚                    â”‚ - N times      â”‚
â”‚ - Check loaded â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ - Health check â”‚                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                             â”‚ Single Inferenceâ”‚
        â–¼                             â”‚ - Start timer  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚ - Call OpenAI  â”‚
â”‚ Model Ready âœ“  â”‚                    â”‚ - Count tokens â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚ - End timer    â”‚
        â”‚                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                      â”‚
        â”‚                             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                             â”‚ Collect Metricsâ”‚
        â”‚                             â”‚ - TPS          â”‚
        â”‚                             â”‚ - TTFT         â”‚
        â”‚                             â”‚ - Latency      â”‚
        â”‚                             â”‚ - Resources    â”‚
        â”‚                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                â”‚ Aggregate   â”‚
                â”‚ Results     â”‚
                â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                â”‚ Save to     â”‚
                â”‚ Storage     â”‚
                â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Results Visualization                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚ Load Results         â”‚
                â”‚ (from storage.json)  â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚ Performance    â”‚                    â”‚ Detailed       â”‚
â”‚ Scores         â”‚                    â”‚ Metrics        â”‚
â”‚ - 0-100 scale  â”‚                    â”‚ - TPS charts   â”‚
â”‚ - Color coded  â”‚                    â”‚ - Latency      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚ - Radar graph  â”‚
                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Model Identifier Flow

```
Storage Model
    â†“
Get from Storage: { id, alias, model_id }
    â†“
Check Loaded in Orchestrator
    â†“
Get SDK Model Info: { id, alias, deviceType, ... }
    â†“
Use modelInfo.alias in OpenAI API
    â†“
âœ… Successful Inference
    â†“
Collect metrics (TPS, latency, tokens)
```

### Test Endpoint Flow

```
User clicks "Test" button
    â”‚
    â–¼
POST /api/models/:id/test
    â”‚
    â”œâ”€â”€â–º Get model from storage
    â”‚       â””â”€â–º model = { id, alias, model_id }
    â”‚
    â”œâ”€â”€â–º Get loaded model info
    â”‚       â””â”€â–º modelInfo = { id, alias, deviceType, ... }
    â”‚
    â”œâ”€â”€â–º Get OpenAI client
    â”‚       â””â”€â–º client = orchestrator.getOpenAIClient()
    â”‚
    â”œâ”€â”€â–º Create request
    â”‚       â””â”€â–º { model: modelInfo.alias, messages: [...] }
    â”‚
    â”œâ”€â”€â–º Call OpenAI API
    â”‚       â””â”€â–º response = await client.chat.completions.create(...)
    â”‚
    â””â”€â”€â–º Return results
            â”œâ”€â–º response: "Hello, I am working!"
            â”œâ”€â–º usage: { completion_tokens: 8, ... }
            â”œâ”€â–º latency: 1234 (ms)
            â””â”€â–º model: "qwen2.5-coder-0.5b"
```

### Quick Usage Summary

1. **Add Models** â†’ Load them â†’ **Test them** âœ¨
2. **Configure Benchmark** â†’ Run it
3. **View Results** â†’ Analyze performance
4. **Export Data** â†’ JSON or CSV

**Key Innovation**: Test button ensures models work before running full benchmarks!
